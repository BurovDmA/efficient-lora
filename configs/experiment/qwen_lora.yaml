# @package _global_

# Example experiment: LoRA fine-tuning for a causal LM on local parquet files.
# Run:
#   python src/train.py experiment=qwen_lora trainer=mps
# Or (GPU):
#   python src/train.py experiment=qwen_lora trainer=gpu

defaults:
  # IMPORTANT: `parquet_lm` requires explicit `data.data_files`.
  # Prefer using one of:
  # - experiment=qwen_lora_math
  # - experiment=qwen_lora_code
  # - experiment=qwen_lora_cooking
  - override /data: oda_math
  - override /model: causal_lm_lora
  - override /callbacks: lm_default
  - override /logger: mlflow
  - override /trainer: mps
  - _self_

tags: ["qwen", "lora", "parquet"]

seed: 42

# Replace with actual Qwen model if you have it locally / via HF:
# model:
#   model_name_or_path: Qwen/Qwen2.5-0.5B-Instruct
#
# If you use an *Instruct* model, enabling chat template is usually better:
# data.use_chat_template is enabled by default in `parquet_lm`

trainer:
  max_epochs: 1
  log_every_n_steps: 5
  # For quick smoke runs you can uncomment:
  # limit_train_batches: 5
  # limit_val_batches: 2

test: False


